# nap.sh   : processes all EDFs/annotations in a folder via NAP
             i.e. calls nap1.sh (potentially batched via LSF)

# napn.sh  : wrapper script called by nap.sh, that calls nap1.sh 1 or more times
             i.e. this implements that concept of batch processing via LSF
             such that it is napn.sh that is sent to LSF (for large datasets, say n=1000, we
             don't want to send a 1000 separate jobs to LSF, but rather using this to send, e.g.
             10 batches of 100 each.    This is determined by the NAP_JOBN value in the default.conf
             The default is 1 which means no submission to LSF (i.e. run on same node).  
             PS.   could use job arrays etc to handle multiple jobs, but this should work just fine 
             at least for now.

# nap1.sh  : operates on a single EDF (and single matching annotation)

# dmerge   : takes results from nap.sh and creates a single table
             i.e. merging across individuals & domains
             see: http://zzz.bwh.harvard.edu/luna/merge/merge

# nap.sh : process folder with 1+ EDFs and annotations
#          creates sample list if it does not exist
#          calls napn.sh (multiple times, potentially with batching)
#          (todo) runs merge to create harmonized datasets across individuals
#
#  arg1 : run name (used to name archived output)
#  arg2 : folder with EDF and XML, or an existing sample list that points to these (s.lst)
#  arg3 : (optional) ID or rows (m,n) to process; or '.' for all rows
#  arg4 : (optional) alternate conf file


# napn.sh : calls nap1.sh one or more times: from n1 to n2 in s.lst
#
#   arg1 : run name
#   arg2 : folder name
#   arg3 : n1 (line in s.lst)
#   arg4 : n2 (line in s.lst)
#   arg5 : alternate conf file


# nap1.sh : implements NAP for a single EDF
#           creates s.lst if id does not exist
#           (can be called standalone, instead of via nap.sh/napn.sh)
#           multiple calls to Luna, and this is where other code will be called from
#           all input from ${folder}  and deteremined by ${folder}/s.lst
#           all outout in ${folder}/nap/${id} which is created by this script
#           calls coda1.R and coda2.R to generate tables and plots for Luna-Shiny
#
#   arg1 : run name
#   arg2 : folder 
#   arg3 : EDF ID (to select from {$folder}/s.lst
#   arg4 : (optional) alternate conf file


# Notes: if an explicit s.lst is not specified, then by default,
# assumes EDF is in form ID.edf and ID.xml and/or ID.annot

# i.e. if data are at :
#   /path/to/nap/user1/upload1/

# e.g. if upload comprises just two files:
#   /path/to/nap/user1/upload1/learn-nsrr01.edf
#   /path/to/nap/user1/upload1/learn-nsrr01.xml

# call to nap.sh will be 

# bash nap.sh {run-label} /path/to/nap/user1/upload1/ 

# this will automatically create an `s.lst` that references these files

# note: currently, the only use of the run-label is to find the group in the 
#       canonical signals file

# after running nap.sh in the background, the output will be in 
#   /path/to/nap/user1/upload1/nap/learn-nsrr01/ 

# i.e. you will generate a link to URL /path/to/nap/user1/upload1/ 
#   and specify which EDF (learn-nsrr01) on the command line
#   the shiny app will then look for the NAP output in 
#      /path/to/nap/user1/upload1/nap/learn-nsrr01/ 
 
#   if the folder contained multiple EDFs, then the above run of nap.sh will create 
#   multiple output folders: 

#      /path/to/nap/user1/upload1/nap/learn-nsrr02/
#      /path/to/nap/user1/upload1/nap/learn-nsrr03/
#   etc


# the individual nap/ folder contains various classes of file, all generated by nap.sh
# 1) .txt and .txt.gz diretly from Luna (or other code, e.g. Matlab)
# 2) .RData files that have that information compiled; these are generated by coda1.R and coda2.R
#    which is called by nap1.sh
# 3) nap.log and nap.err & nap.status
# 4) annots/ folder
# 4) data/ folder with new EDFs
# 5) two new sample lists, harm.lst and base.lst

# e.g.
# ~/tmp/data/user1/example1/nap/learn-nsrr01/                                                                                    

# luna_core_HEADERS_CH.txt
# luna_core_HEADERS.txt
# --> HEADERS-tab.RData

# luna_macro_HYPNO.txt
# luna_macro_HYPNO_C.txt
# luna_macro_HYPNO_E.txt
# --> HYPNO-tab.RData

# luna_spec_PSD_B_CH_SS-N2.txt
# luna_spec_PSD_B_CH_SS-N23.txt
# --> PSD-tab.RData



# NAP CONFIGURATIONS
# During NAP run time, user can provide alternate configuration
# with any/all of the variables defined in the configuration file.
#
# Job with alternate config file can be invoked as
# bash nap.sh {run-label} /path/to/nap/user1/upload1/ {alternate-config-file}
#
# Below is the explaination of each variable,
#
#  NAP_VERSION
#  Recommended to keep the default value.
#  This variable is used to log process start and complete with version info in nap.log file
#
#  NAP_DATE
#  Recommended to keep the default value.
#  This variable defines the date of release of the NAP version as defined in NAP_VERSION variable.
#
#  NAP_RESOURCE_DIR
#  Not in use currently, keep the default value.
#  This variable points to the folder containing additional resources required for NAP
#
#  NAP_DEF_DIR
#  This variable points to the directory with Signals canonical, Signals alias, Signals groups and Annotation alias files.
#  For NSRR specific studies, keep the default value.
#
#  NAP_LUNA
#  Path to Luna binary/executable on the local system of NAP deployment
#
#  NAP_DESTRAT
#  Path to Destrat binary/executable on the local system of NAP deployment
#
#  NAP_FIXROWS
#  Path to Fixrows binary/executable on the local system of NAP deployment
#
#  NAP_R
#  Path to Rscript binary/executable on the local system of NAP deployment
#
#  NAP_JOBN
#  This variable defines the count of jobs to run NAP in parallel.
#  Specific to IBM LSF cluster. Can be ignored in other use-cases.
#
#  NAP_LSF_QUEUE
#  This variable defines the queue name to run NAP.
#  Specific to IBM LSF queue name. Can be ignored in other use-cases.
#
#  NAP_LSF_RUSAGE
#  This variable define the run time memory configuration to run NAP.
#  Specific to IBM LSF node memory configuration. Can be ignored in other use-cases.
#
#  NAP_LSF_NODES
#  This variable defines the node names to run NAP.
#  Specific to IBM LSF node names. Can be ignored in other use-cases.
#
#  NAP_LUNA_ARGS
#  This variable defines the parameter file to be passed to NAP.
#  Refer to http://zzz.bwh.harvard.edu/luna/luna/args/#parameter-files for additional info.
#
#  NAP_OUTPUT
#  This variable defines the non-standard output type for NAP.
#  Useful in cases (Seven Bridges platform) where there is a need to write output to the home folder.
#  Value can be "FILE" or "DIRECTORY" (in all caps)
#  If value is "FILE", then NAP outputs a .tar.gz file with name as a combination of run name and start time.
#  If values is "DIRECTORY", then NAP outputs a directory with name as a combination of run name and start time.
#
#  NAP_AWS_PORTAL_MODE
#  This variable represents if the Portal mode is turned on (for Portal use case only)
#  Values are 1,0 for on/off
#
#  NAP_AWS_CLI
#  This variable list the path to AWS cli installed location (for Portal use case only)
#
#  NAP_AWS_PROFILE
#  This variable represents the AWS named profile for copying sample list to s3 bucket (for Portal use case only)
#
#  NAP_SLST_BUILD_FLAGS
#  This variable represents the Luna Sample list build flag. 
#  Refer to http://zzz.bwh.harvard.edu/luna/luna/args/#-build-option for additional info 
#
#  NAP_MATLAB
#  This variable list the path to matlab installed location
#
#  NAP_RESP
#  This variable represents if respiratory analysis is enabled or not
#  Values are 1,0 for on/off
